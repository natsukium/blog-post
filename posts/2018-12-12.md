---
layout: post
title: Predicting Organic Reaction Outcomes with Weisfeiler-Lehman Network [Nips, 2017]
author: natsukium
published: 2018-12-12
slug: journal-club
tags: deep, chem
description: 有機化学反応をDeep Learningで予測する話
---

[今年読んだ一番好きな論文2018 Advent Calendar](https://adventar.org/calendars/3392) 12日目の記事です.
<blockquote class="embedly-card"><h4><a href="https://adventar.org/calendars/3392">今年読んだ一番好きな論文2018 Advent Calendar 2018 - Adventar</a></h4><p>学生の方々に、今年読んで驚いた・インパクトのあった・面白かったなど、とにかく一番好きな論文を紹介していただくプロジェクトです。素敵な論文紹介には賞も授与されます。参加賞も予定していますので、どしどし参加してください。 学生限定です(社会人学生の方、DCの方も勿論OK!)。今年読んだ一番好きな論文を紹介しましょう！運営 twitter: @kebabfiesta ...</p></blockquote>
<script async src="//cdn.embedly.com/widgets/platform.js" charset="UTF-8"></script>

今回紹介する論文は次の論文です.

Predicting Organic Reaction Outcomes with Weisfeiler-Lehman Network[[8]](#8).

ざっくり言うと低分子の化学反応を**無敵のDeep Learning**で再現しちゃおう！という論文です.
反応物が与えられた時にどのような生成物が得られるかを予測するタスクで,
化合物をグラフ構造として突っ込んで学習させる昨今流行りで主流となっているGraph Convolutionの類ですね.
学部の有機化学の講義で電子の気持ちがわからず諦めた経験のある僕にとってはこのようなネットワークに期待するしかありません.

ちなみに今年は既に2件も低分子と深層学習の紹介がありケモインフォは皆が注目する熱い分野のようです.
参考までにどうぞ.

> [[文献紹介] Chemical Heteroencoder](https://qiita.com/shionhonda/items/a748840b1a32e4812129) [[4]](#4)
>
> [論文紹介 : Molecular Graph Convolutions](https://ot0eu.hatenablog.com/entry/2018/12/09/054023) [[7]](#7)

ちなみに後から気づいたのですがこれの改訂版が存在し, それはChemRxivから取得できるそうです[W. Coley+, 2018][[2]](#2).
タイトルもファーストオーサーも変わってますね, ややこしい.
中身も書きかわっているようですが, 実験概要などは変わっていない(はず)なのでNips ver.を紹介していきます.
改訂版との重要な差分があれば後ほど追記していきたいと思います.
(よく見ると結合様式を考慮する？ようになって精度上がってますね...)
完全に別論文なのでは！？

## 概要
中身に入る前にどのような反応を予測できたのか示しておきます.

![result](https://raw.githubusercontent.com/natsukium/blog-post/master/images/2018-12-12/result.png)

なお, この図は改訂版の Fig. 5 を引用しています.
黄緑色の原子が反応中心となる原子を表しており, 青色はその部分に対して反応性の高い原子を表しています.
濃いほど高い反応性を有すると判断された原子となっています.
インプットとして溶媒や触媒も含まれているようですがしっかり反応物を見分けて学習できていそうです.


## 背景
有機化学反応の生成物予測はこれまでも行われてきましたが, 時には数百もの原子が反応に関与するため探索空間が非常に大きく,
予測が困難であるという問題がありました.
そこで反応機構(template)を学習させ, 探索空間を狭めるという手法が主に使われてきました.
これをTemplate-basedといい, このtemplateは職人の温かみのある手によって大事に作られるか,
或いはデータベースからヒューリスティックなアルゴリズムによって作成されています.
しかし, このTemplate-basedな手法では正しい生成物を予測するために大量のtemplateを必要とし,
そのために非効率的であるという問題を抱えています.
従来手法は限られた反応機構のみを収録したサイズの大きくないデータセット以外に対して有効ではありませんでした.

### 課題
本論文で解決したい主な課題は以下の3点です.
- 膨大な生成物空間を効率よく制限し, 容易に探索できるようにしたい.
- 候補となる化合物の中から実際の生成物を見つけたい.
- データセットをスケールしたい.

それではどうやってクリアしていくか見ていきましょう.

## 前提知識
その前に少し知識の整理をしましょう.
### Reaction SMILES
SMILESについては既に紹介されているのでここでは省略します.
Reaction SMILESとはSMILES記法を反応式に拡張したもので, 簡単なエステル化は次のように記述されます.

CC(=O)O.OCC>[H+].[Cl-].OCC>CC(=O)OCC

![reaction](https://raw.githubusercontent.com/natsukium/blog-post/master/images/2018-12-12/reaction.png)

化合物をSMILES記法で表し, それを次の様式で記述します.

反応物1.反応物2>触媒>生成物

なお, 触媒が必要ない場合や省略する場合は

反応物>>生成物

と表せます.
化学反応式をこのように記述する方法があるというのを初めて知りました.

今回の実験で用いるUSPTO[[3]](#3)というデータセットがこの形式で記述されています.

### Graph Convolution
Graph Convolutionがどのような技術なのかわからない方も多いと思いますので,
一般的なネットワークのイメージを共有しておきます.
なお, 本論文紹介は多様なバックグラウンドを持つ方々に向けたものという位置付けのため,
本論文で用いられているWLNの詳細については省かせていただきます.
こちらに関しては後ほど紹介するかもしれませんし, 実装して公開するかもしれません.
興味ある方は圧力をかけていただけると幸いです.

Graph Convolutionの説明で必ずと言っていいほど使われる図を引用します[Han Altae-tran+, 2017][[5]](#5).

![gc](https://raw.githubusercontent.com/natsukium/blog-post/master/images/2018-12-12/gc.png)

それぞれの化合物について原子ごとの特徴ベクトル(atomic features), 各原子が隣接しているかどうかを表す隣接行列をネットワークに流していきます.

1. まず, 化合物の中から一つの原子を選びます.
1. その原子についての特徴ベクトルをある重みに従って線形変換します. さらにその原子に隣接する原子の特徴ベクトルも同じ重みを用いて線形変換します.
1. 次にこれらの特徴ベクトルを足し合わせ, さらにシグモイドやReLUなどの活性化関数を通します.
1. 最後に変換されたベクトルを次の層における原子の特徴ベクトルとします.

これらの操作を全ての原子について行い, 次の層のインプットを作ります.

ネットワークの設計によっては細かい部分が変わったりしますが,
Graph Convolutionの大きな枠組みはだいたいこのようなものになります.
このようにすることによって原子一つだけの情報ではなくその周囲の情報も織り込み,
層を重ねるごとに遠く離れた原子の情報も反映した特徴ベクトルを構成することができるようになります.

また, 興味のある方はMessage Passing Neural Networks[J. Gilmer+, 2017][[6]](#6)を学習すると統一的に理解できるかもしれません.

## 手法
![wln](https://raw.githubusercontent.com/natsukium/blog-post/master/images/2018-12-12/wln.png)

この論文では生成物の予測に際して次の3ステップを用意してあります.
1. 反応中心の予測
1. 候補化合物の生成
1. 候補化合物のランクづけ

### 反応中心の予測
本手法では反応中心の予測にLocalとGlobalの二つのモデルを用います.
Localモデルはその名前の通り原子周辺のみの情報を集め, その原子が反応中心であるかどうか判断します.
ただしこれだけでは誤った局所的な解に陥る可能性があるのでGlobalモデルによって制約をかけます.
Globalモデルもまたその名の通り, 反応中心ではないがその反応が起こるために必要である可能性のある遠くにある原子の影響を考慮して, 反応中心かどうかを判断します.
これら二つのネットワークの出力を同時に最適化することによって反応における真の反応中心を見つけだします.

このときの原子ペアの反応のしやすさをスコア化したものが上の図にあります.

### 候補化合物の生成
スコア化した原子ペアのうち, トップからK個選びます. このK個のペアについて全ての組み合わせを試し,
結合法則にそぐわないもの(原子価を超えて結合したものなど)を弾いていきます.

### 候補化合物のランクづけ
反応物と生成物(真の生成物と候補化合物)のグラフとしての差異のようなものをスコア化し,
真の生成物とのスコアが最大となるように学習します.
この中身については主題であるWeisfeiler-Lehman Networkの説明を省いてしまったので詳細には触れられません...
しかしこの論文の重要な部分なので気が向いたら別記事で書きます.
このときスコア化の仕方によってこの後の結果に出てくるWLNとWLDNに分かれるのですが,
WLDNの方が丁寧にスコア化したものと捉えてください.

真の生成物とのスコアが最大となるように学習されたとき, 正例が与えられない状態でも正しい生成物を提案することが可能となります.

## 実験
### データセット
今回はUSPTO[[3]](#3)という48万件の反応式がReaction SMILESの形式で記されたデータセットを用いました.
これを訓練用, 評価用, テスト用にそれぞれ40万, 4万, 4万となるように分けます.
さらにベースライン[Coley+, 2017][[1]](#1)との比較のため48万件の反応の中から1万5千件の反応を抽出したUSPTO-15Kというデータセットも用意しました.
この中には1,700件の基礎的な反応テンプレートが含まれており, 10,500, 1,500, 3,000件に分割してあります.

## 結果
![USPTO](https://raw.githubusercontent.com/natsukium/blog-post/master/images/2018-12-12/USPTO.png)

左側は反応中心の予測, 右側は候補化合物の予測の結果を表しています.
反応中心の予測の数値はcoverageを表していて, 提案した反応中心が実際の反応中心を当てる割合を示しています.
K=8のとき, Globalモデルでは平均246.5個の候補化合物を提案しますが, これはTemplate-basedな手法で得られる482.3個よりも随分と少なく済みます.
このときのcoverageは90%を超えており, 精度を落とすことなく従来手法よりコストを削減できていることがわかります.
さらにUSPTO-15KとUSPTOの結果を比べてもcoverageは下がることなく, データセットのスケールにも対応していることがわかります.

候補化合物の予測の数値は精度を表しています. ベースラインはcoverageが100となるように最適化されているため,
提案手法でもcoverageを100になるように学習したものが(*)のついた項です.
P@1, P@3, P@5はそれぞれスコアが上位1, 3, 5番目までの候補化合物が正解している割合を示しています.
これらから, ほぼ精度を保ったまま高速化ができており, さらに精度を重視した場合には圧倒的に上回る性能を持っていることがわかります.
さらにデータセットのスケールに対しても問題なく対応しています.

### 人間との比較
テスト用のデータから80個の反応をランダムに選択し, 10人の化学者にそれぞれの反応の生成物を予測してもらいました.
その結果が次の表です.

![human](https://raw.githubusercontent.com/natsukium/blog-post/master/images/2018-12-12/human.png)

人間...不要なのでは？
そもそも正答率16.3%の人は結果に真摯に向き合った方が良いと思いますね.

## まとめ
Template-basedな手法より140倍も高速に学習でき, データセットのスケールにも対応した最強のネットワークが提案されました.

また, Graph Convolutionを使った**無敵のDeep Learning**で人間を越えることができました.

## 参考文献
<a id="1"></a>
[1] Connor W Coley, Regina Barzilay, Tommi S Jaakkola, William H Green, and Klavs F Jensen. [Prediction of organic reaction outcomes using machine learning](https://pubs.acs.org/doi/10.1021/acscentsci.7b00064). *ACS Cent. Sci.*, 2017, 3, 5, 434-443.

<a id="2"></a>
[2] Connor W. Coley, Wengong Jin, Luke Rogers, Timothy F. Jamison, Tommi S. Jaakkola, William H. Green, Regina Barzilay, Klavs F. Jensen. [A Graph-Convolutional Neural Network Model for the Prediction of Chemical Reactivity](https://chemrxiv.org/articles/A_Graph-Convolutional_Neural_Network_Model_for_the_Prediction_of_Chemical_Reactivity/7163189/1). *ChemRxiv*, 2018.

<a id="3"></a>
[3] D. M. Lowe. Patent reaction extraction: downloads; <https://bitbucket.org/dan2097/patent-reaction-extraction/downloads>. 2014.

<a id="4"></a>
[4] Esben Jannik Bjerrum, Boris Sattarov. [Improving Chemical Autoencoder Latent Space and Molecular De novo Generation Diversity with Heteroencoders](https://arxiv.org/abs/1806.09300). *arXiv:1806.09300*, 2018.

<a id="5"></a>
[5] Han Altae-Tran, Bharath Ramsundar , Aneesh S. Pappu, and Vijay Pande. [Low Data Drug Discovery with One-Shot Learning](https://pubs.acs.org/doi/10.1021/acscentsci.6b00367). *ACS Cent. Sci.*, 2017, 3, 4, 283-293.

<a id="6"></a>
[6] Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, George E. Dahl. [Neural Message Passing for Quantum Chemistry](https://arxiv.org/abs/1704.01212). *arXiv:1704.01212*, 2017.

<a id="7"></a>
[7] Steven Kearnes, Kevin McCloskey, Marc Berndl, Vijay Pande, Patrick Riley. [Molecular Graph Convolutions: Moving Beyond Fingerprints](https://arxiv.org/abs/1603.00856). *arXiv:1603.00856*, 2016.

<a id="8"></a>
[8] Wengong Jin, Connor W. Coley, Regina Barzilay, Tommi Jaakkola. [Predicting Organic Reaction Outcomes with Weisfeiler-Lehman Network](https://arxiv.org/abs/1709.04555). *arXiv:1709.04555*, 2017.
